"""
AISCA - Moteur d'Analyse S√©mantique
√âtapes 3 & 4 : Semantic Matching + Calcul de Score
Utilise SBERT pour analyse s√©mantique des comp√©tences
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import json
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')


class SemanticAnalyzer:
    """
    Classe principale pour l'analyse s√©mantique des comp√©tences
    Impl√©mente SBERT pour le matching s√©mantique
    """
    
    def __init__(self, competencies_path='data/competencies.csv', jobs_path='data/jobs.csv'):
        """
        Initialiser l'analyseur s√©mantique
        
        Args:
            competencies_path: Chemin vers competencies.csv
            jobs_path: Chemin vers jobs.csv
        """
        print("üîÑ Initialisation du moteur d'analyse s√©mantique...")
        
        # Charger le mod√®le SBERT multilingue
        print("üì• Chargement du mod√®le SBERT...")
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        # Charger les donn√©es
        print("üìÇ Chargement des comp√©tences et m√©tiers...")
        self.competencies_df = pd.read_csv(competencies_path)
        self.jobs_df = pd.read_csv(jobs_path)
        
        # Cr√©er les embeddings des comp√©tences (une seule fois)
        print("üß† Cr√©ation des embeddings des comp√©tences...")
        self._create_competency_embeddings()
        
        # Variables pour stocker les r√©sultats
        self.user_responses = None
        self.block_scores = {}
        self.detected_competencies = {}
        self.coverage_score = 0.0
        self.recommended_jobs = []
        
        print("‚úÖ Initialisation termin√©e !\n")
    
    
    def _create_competency_embeddings(self):
        """
        √âTAPE 3 : Cr√©er les embeddings pour toutes les comp√©tences
        Combine le nom court + description pour un meilleur matching
        """
        self.competency_texts = []
        self.competency_ids = []
        
        for _, row in self.competencies_df.iterrows():
            # Combiner nom de comp√©tence + description pour contexte riche
            text = f"{row['Competency']} {row['Description']}"
            self.competency_texts.append(text)
            self.competency_ids.append(row['CompetencyID'])
        
        # Encoder toutes les comp√©tences en une seule fois (efficace)
        self.competency_embeddings = self.model.encode(
            self.competency_texts,
            convert_to_tensor=True,
            show_progress_bar=True
        )
        
        print(f"‚úÖ {len(self.competency_embeddings)} embeddings de comp√©tences cr√©√©s")
    
    
    def analyze_user_responses(self, responses: Dict):
        """
        Analyser les r√©ponses du questionnaire utilisateur
        
        Args:
            responses: Dictionnaire des r√©ponses par bloc
        """
        print("\nüîç ANALYSE DES R√âPONSES UTILISATEUR")
        print("=" * 60)
        
        self.user_responses = responses
        
        # Analyser chaque bloc
        for bloc_id in range(1, 6):
            bloc_key = f'bloc{bloc_id}'
            if bloc_key in responses:
                print(f"\nüìä Analyse du Bloc {bloc_id}...")
                self._analyze_bloc(bloc_id, responses[bloc_key])
        
        # Calculer le coverage score global
        self._calculate_global_coverage_score()
        
        # Recommander les m√©tiers
        self._recommend_jobs()
        
        print("\n‚úÖ Analyse termin√©e !")
        print("=" * 60)
    
    
    def _analyze_bloc(self, bloc_id: int, bloc_responses: Dict):
        """
        √âTAPE 3 & 4 : Analyser un bloc sp√©cifique
        Calcule le score de similarit√© s√©mantique
        
        Args:
            bloc_id: Num√©ro du bloc (1-5)
            bloc_responses: R√©ponses pour ce bloc
        """
        # R√©cup√©rer toutes les comp√©tences du bloc
        bloc_competencies = self.competencies_df[
            self.competencies_df['BlockID'] == bloc_id
        ]
        
        # ========================================
        # √âTAPE 3.1 : ANALYSE S√âMANTIQUE TEXTE LIBRE
        # ========================================
        text_key = f'q{bloc_id*4-2}_text'  # Question texte libre
        user_text = bloc_responses.get(text_key, '')
        
        sbert_score = 0.0
        detected_comps = []
        
        if user_text and len(user_text.strip()) > 0:
            # Encoder le texte utilisateur
            user_embedding = self.model.encode(user_text, convert_to_tensor=True)
            
            # Calculer similarit√©s avec toutes les comp√©tences du bloc
            similarities = []
            for _, comp_row in bloc_competencies.iterrows():
                comp_idx = self.competency_ids.index(comp_row['CompetencyID'])
                comp_embedding = self.competency_embeddings[comp_idx]
                
                # Similarit√© cosinus
                similarity = util.cos_sim(user_embedding, comp_embedding).item()
                similarities.append({
                    'competency_id': comp_row['CompetencyID'],
                    'competency_name': comp_row['Competency'],
                    'similarity': similarity
                })
            
            # Filtrer les comp√©tences avec similarit√© > 0.3 (seuil)
            detected_comps = [
                comp for comp in similarities 
                if comp['similarity'] > 0.3
            ]
            
            # Score SBERT = moyenne des top similarit√©s
            if detected_comps:
                top_similarities = sorted(
                    [c['similarity'] for c in detected_comps],
                    reverse=True
                )[:10]  # Top 10 comp√©tences
                sbert_score = np.mean(top_similarities)
            
            print(f"  üìù Texte libre analys√© : {len(detected_comps)} comp√©tences d√©tect√©es")
            print(f"  üéØ Score SBERT : {sbert_score:.3f}")
        
        # ========================================
        # ANALYSE LIKERT (Auto-√©valuation)
        # ========================================
        likert_key = f'q{bloc_id*4-3}_likert'
        likert_value = bloc_responses.get(likert_key, 0)
        likert_score = likert_value / 5.0  # Normaliser √† [0, 1]
        
        print(f"  üìä Score Likert : {likert_score:.3f} (niveau {likert_value}/5)")
        
        # ========================================
        # ANALYSE CHOIX MULTIPLE (OUTILS)
        # ========================================
        tools_key = f'q{bloc_id*4-1}_tools'
        selected_tools = bloc_responses.get(tools_key, [])
        
        # Score tools = proportion s√©lectionn√©e (hors "Aucun")
        if selected_tools and "Aucun" not in selected_tools and "Aucune" not in selected_tools:
            tools_score = min(len(selected_tools) / 6.0, 1.0)  # Max 1.0
        else:
            tools_score = 0.0
        
        print(f"  üîß Score Outils : {tools_score:.3f} ({len(selected_tools)} outils)")
        
        # ========================================
        # ANALYSE CASES COCH√âES (COMP√âTENCES)
        # ========================================
        checkbox_key = f'q{bloc_id*4}_competences'
        if bloc_id == 2:
            checkbox_key = f'q{bloc_id*4}_algorithmes'
        elif bloc_id == 3:
            checkbox_key = f'q{bloc_id*4}_techniques'
        elif bloc_id == 5:
            checkbox_key = f'q{bloc_id*4}_domaines'
        
        checked_items = bloc_responses.get(checkbox_key, [])
        
        if checked_items and "Aucun" not in checked_items and "Aucune" not in checked_items:
            checkbox_score = min(len(checked_items) / 10.0, 1.0)
        else:
            checkbox_score = 0.0
        
        print(f"  ‚òëÔ∏è  Score Comp√©tences : {checkbox_score:.3f} ({len(checked_items)} items)")
        
        # ========================================
        # √âTAPE 4 : CALCUL DU SCORE POND√âR√â (4 COMPOSANTES)
        # ========================================
        weights = {
            'sbert': 0.40,      # 40% - Analyse s√©mantique
            'likert': 0.25,     # 25% - Auto-√©valuation
            'checkbox': 0.20,   # 20% - Comp√©tences coch√©es
            'tools': 0.15       # 15% - Outils s√©lectionn√©s
        }
        
        bloc_score = (
            weights['sbert'] * sbert_score +
            weights['likert'] * likert_score +
            weights['checkbox'] * checkbox_score +
            weights['tools'] * tools_score
        )
        
        print(f"  ‚≠ê SCORE FINAL BLOC {bloc_id} : {bloc_score:.3f}")
        
        # Stocker les r√©sultats
        self.block_scores[f'bloc{bloc_id}'] = {
            'score': bloc_score,
            'sbert_score': sbert_score,
            'likert_score': likert_score,
            'checkbox_score': checkbox_score,
            'tools_score': tools_score,
            'detected_competencies': detected_comps
        }
        
        self.detected_competencies[f'bloc{bloc_id}'] = detected_comps
    
    
    def _calculate_global_coverage_score(self):
        """
        √âTAPE 4 : Calculer le Coverage Score global
        Formule : moyenne pond√©r√©e des 5 blocs
        """
        print("\n" + "=" * 60)
        print("üìä CALCUL DU COVERAGE SCORE GLOBAL")
        print("=" * 60)
        
        # Poids par d√©faut = 1 pour tous les blocs (importance √©gale)
        weights = {
            'bloc1': 1.0,
            'bloc2': 1.0,
            'bloc3': 1.0,
            'bloc4': 1.0,
            'bloc5': 1.0
        }
        
        # Calcul avec formule du PDF
        numerator = sum(
            weights[bloc_key] * self.block_scores[bloc_key]['score']
            for bloc_key in self.block_scores
        )
        denominator = sum(weights.values())
        
        self.coverage_score = numerator / denominator
        
        print(f"\n‚ú® COVERAGE SCORE GLOBAL : {self.coverage_score:.3f}")
        print("=" * 60)
        
        # Afficher d√©tails
        print("\nüìã D√©tail des scores par bloc :")
        for bloc_key in sorted(self.block_scores.keys()):
            score = self.block_scores[bloc_key]['score']
            print(f"  ‚Ä¢ {bloc_key.upper()} : {score:.3f}")
    
    
    def _recommend_jobs(self):
        """
        √âTAPE 5 : Recommander les 3 meilleurs m√©tiers
        Match le profil utilisateur avec les 15 m√©tiers
        """
        print("\n" + "=" * 60)
        print("üéØ RECOMMANDATION DES M√âTIERS")
        print("=" * 60)
        
        job_scores = []
        
        for _, job_row in self.jobs_df.iterrows():
            job_id = job_row['JobID']
            job_title = job_row['JobTitle']
            required_comps = job_row['RequiredCompetencies'].split(';')
            
            # Calculer le score de match pour ce m√©tier
            match_score = self._calculate_job_match(required_comps)
            
            job_scores.append({
                'job_id': job_id,
                'job_title': job_title,
                'match_score': match_score,
                'required_competencies': required_comps
            })
        
        # Trier par score d√©croissant
        job_scores.sort(key=lambda x: x['match_score'], reverse=True)
        
        # TOP 3
        self.recommended_jobs = job_scores[:3]
        
        print("\nüèÜ TOP 3 M√âTIERS RECOMMAND√âS :")
        for i, job in enumerate(self.recommended_jobs, 1):
            print(f"  {i}. {job['job_title']} - Score : {job['match_score']:.1f}%")
        
        print("=" * 60)
    
    
    def _calculate_job_match(self, required_competencies: List[str]) -> float:
        """
        Calculer le score de match entre profil utilisateur et un m√©tier
        
        Args:
            required_competencies: Liste des IDs de comp√©tences requises
            
        Returns:
            Score de match en pourcentage (0-100)
        """
        if not required_competencies:
            return 0.0
        
        total_score = 0.0
        
        for comp_id in required_competencies:
            comp_id = comp_id.strip()
            
            # Trouver le bloc de cette comp√©tence
            comp_row = self.competencies_df[
                self.competencies_df['CompetencyID'] == comp_id
            ]
            
            if comp_row.empty:
                continue
            
            bloc_id = comp_row.iloc[0]['BlockID']
            bloc_key = f'bloc{bloc_id}'
            
            # Score du bloc correspondant
            if bloc_key in self.block_scores:
                bloc_score = self.block_scores[bloc_key]['score']
                
                # V√©rifier si comp√©tence sp√©cifiquement d√©tect√©e
                detected_comps = self.detected_competencies.get(bloc_key, [])
                detected_ids = [c['competency_id'] for c in detected_comps]
                
                if comp_id in detected_ids:
                    # Boost si comp√©tence sp√©cifiquement d√©tect√©e
                    comp_score = min(bloc_score * 1.2, 1.0)
                else:
                    comp_score = bloc_score
                
                total_score += comp_score
        
        # Score moyen en pourcentage
        match_percentage = (total_score / len(required_competencies)) * 100
        
        return match_percentage
    
    
    def get_results_summary(self) -> Dict:
        """
        Obtenir un r√©sum√© complet des r√©sultats
        
        Returns:
            Dictionnaire avec tous les r√©sultats
        """
        return {
            'coverage_score': self.coverage_score,
            'block_scores': self.block_scores,
            'detected_competencies': self.detected_competencies,
            'recommended_jobs': self.recommended_jobs
        }
    
    
    def save_results(self, filepath=None):
        """
        Sauvegarder les r√©sultats dans un fichier JSON
        
        Args:
            filepath: Chemin du fichier de sortie (optionnel)
        """
        import os
        from datetime import datetime
        
        # Cr√©er le dossier responses s'il n'existe pas
        os.makedirs('responses', exist_ok=True)
        
        # Nom de fichier par d√©faut avec timestamp
        if filepath is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = f"responses/results_{timestamp}.json"
        
        results = self.get_results_summary()
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ R√©sultats sauvegard√©s dans {filepath}")


# ============================================
# FONCTIONS UTILITAIRES
# ============================================

def load_responses_from_file(filepath: str) -> Dict:
    """
    Charger les r√©ponses depuis un fichier JSON
    
    Args:
        filepath: Chemin vers le fichier de r√©ponses
        
    Returns:
        Dictionnaire des r√©ponses
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data['responses']


# ============================================
# EXEMPLE D'UTILISATION
# ============================================

if __name__ == "__main__":
    # Test du moteur d'analyse
    print("\n" + "=" * 60)
    print("üß™ TEST DU MOTEUR D'ANALYSE S√âMANTIQUE")
    print("=" * 60)
    
    # Initialiser l'analyseur
    analyzer = SemanticAnalyzer()
    
    # Exemple de r√©ponses (√† remplacer par vraies r√©ponses du questionnaire)
    example_responses = {
        'bloc1': {
            'q1_likert': 4,
            'q2_text': "J'ai une grande exp√©rience en analyse de donn√©es avec Python et Pandas. J'ai cr√©√© des dashboards interactifs avec Plotly pour visualiser les KPIs de vente.",
            'q3_tools': ['Matplotlib', 'Seaborn', 'Plotly'],
            'q4_competences': ['Data cleaning (nettoyage de donn√©es)', 'Manipulation avec Pandas', 'Requ√™tes SQL']
        },
        'bloc2': {
            'q5_likert': 3,
            'q6_text': "J'ai d√©velopp√© des mod√®les de pr√©diction avec Random Forest et XGBoost. J'optimise les hyperparam√®tres avec GridSearch.",
            'q7_tools': ['Scikit-learn', 'XGBoost'],
            'q8_algorithmes': ['Random Forest', 'Gradient Boosting (XGBoost, LightGBM)']
        },
        'bloc3': {
            'q9_likert': 2,
            'q10_text': "J'ai utilis√© K-means pour segmenter des clients et PCA pour visualiser.",
            'q11_tools': ['Scikit-learn (clustering, PCA)'],
            'q12_techniques': ['K-means clustering', 'PCA (Principal Component Analysis)']
        },
        'bloc4': {
            'q13_likert': 4,
            'q14_text': "J'ai d√©velopp√© un chatbot avec SBERT pour analyse s√©mantique. J'utilise des transformers pour la classification de texte et l'analyse de sentiments.",
            'q15_tools': ['Transformers (Hugging Face)', 'Sentence-Transformers (SBERT)'],
            'q16_competences': ['SBERT (Sentence-BERT)', 'BERT / Transformers', 'Sentiment analysis']
        },
        'bloc5': {
            'q17_likert': 3,
            'q18_text': "Je ma√Ætrise les tests statistiques (t-test, ANOVA) et l'alg√®bre lin√©aire pour comprendre les algorithmes ML.",
            'q19_tools': ['NumPy', 'SciPy'],
            'q20_domaines': ['Tests d\'hypoth√®ses (t-test, chi-carr√©, ANOVA)', 'Alg√®bre lin√©aire (matrices, vecteurs propres)']
        }
    }
    
    # Analyser les r√©ponses
    analyzer.analyze_user_responses(example_responses)
    
    # Afficher les r√©sultats
    results = analyzer.get_results_summary()
    
    print("\n" + "=" * 60)
    print("üìä R√âSUM√â DES R√âSULTATS")
    print("=" * 60)
    print(f"Coverage Score Global : {results['coverage_score']:.3f}")
    print(f"M√©tiers recommand√©s : {len(results['recommended_jobs'])}")
    
    print("\n‚úÖ Test termin√© !")