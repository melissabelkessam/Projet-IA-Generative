"""
Moteur d'analyse s√©mantique SBERT
√âtape 3 : Correspondance s√©mantique (Semantic Matching)
Version am√©lior√©e : Utilise textes libres + t√¢ches + outils
"""

import pandas as pd
import json
import os
from sentence_transformers import SentenceTransformer, util
import numpy as np

# =========================
# Configuration
# =========================
COMPETENCIES_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "competencies.csv")
USER_RESPONSES_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "user_responses.json")
SBERT_MODEL = "all-MiniLM-L6-v2"

# =========================
# Fonction 1 : Charger et concat√©ner les comp√©tences par bloc
# =========================
def load_and_concatenate_blocks():
    """
    Charge le r√©f√©rentiel de comp√©tences et concat√®ne toutes les comp√©tences
    de chaque bloc en une seule grande cha√Æne de texte.
    
    Retourne un dictionnaire : {BlockID: texte_concat√©n√©}
    """
    print("üìÇ Chargement du r√©f√©rentiel de comp√©tences...")
    df = pd.read_csv(COMPETENCIES_PATH)
    
    blocks_text = {}
    
    # Regrouper par BlockID
    for block_id in sorted(df['BlockID'].unique()):
        # Prendre toutes les comp√©tences du bloc
        competencies = df[df['BlockID'] == block_id]['Competency'].tolist()
        
        # Concat√©ner toutes les comp√©tences en une seule phrase
        blocks_text[block_id] = ' '.join(competencies)
        
        block_name = df[df['BlockID'] == block_id]['BlockName'].iloc[0]
        print(f"   ‚úÖ Bloc {block_id} ({block_name}) : {len(competencies)} comp√©tences")
    
    return blocks_text

# =========================
# Fonction 2 : Charger les r√©ponses utilisateur (VERSION AM√âLIOR√âE)
# =========================
def load_user_responses():
    """
    Charge les r√©ponses utilisateur depuis le JSON.
    Extrait :
    - Les textes libres (_text)
    - Les t√¢ches ma√Ætris√©es (_tasks)
    - Les outils ma√Ætris√©s (_tools)
    
    Retourne un texte enrichi combinant toutes ces informations.
    """
    print("\nüìÇ Chargement des r√©ponses utilisateur...")
    
    with open(USER_RESPONSES_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Prendre la derni√®re r√©ponse soumise
    if isinstance(data, list):
        user_data = data[-1]  # Derni√®re soumission
    else:
        user_data = data
    
    responses = user_data.get('responses', {})
    
    # Listes pour stocker les diff√©rents types de r√©ponses
    user_texts = []
    user_tasks = []
    user_tools = []
    
    # Parcourir toutes les r√©ponses
    for key, value in responses.items():
        
        # 1. Textes libres
        if key.endswith('_text') and isinstance(value, str) and value.strip() != "":
            user_texts.append(value)
            print(f"   ‚úÖ Texte trouv√© : {value[:50]}...")
        
        # 2. T√¢ches (listes)
        elif key.endswith('_tasks') and isinstance(value, list):
            # Filtrer "Aucune de ces t√¢ches"
            filtered_tasks = [task for task in value if task != "Aucune de ces t√¢ches"]
            if filtered_tasks:
                user_tasks.extend(filtered_tasks)
                print(f"   üéØ T√¢ches : {', '.join(filtered_tasks)}")
        
        # 3. Outils (listes)
        elif key.endswith('_tools') and isinstance(value, list):
            if value:
                user_tools.extend(value)
                print(f"   üõ†Ô∏è Outils : {', '.join(value)}")
    
    # Combiner tout en un seul texte enrichi
    combined_parts = []
    
    if user_texts:
        combined_parts.append(' '.join(user_texts))
    
    if user_tasks:
        combined_parts.append(' '.join(user_tasks))
    
    if user_tools:
        combined_parts.append(' '.join(user_tools))
    
    combined_user_text = ' '.join(combined_parts)
    
    print(f"\nüìù Texte enrichi total : {len(combined_user_text)} caract√®res")
    print(f"   - {len(user_texts)} textes libres")
    print(f"   - {len(user_tasks)} t√¢ches")
    print(f"   - {len(user_tools)} outils")
    
    return combined_user_text

# =========================
# Fonction 3 : Calculer la similarit√© s√©mantique
# =========================
def calculate_semantic_similarity(user_text, blocks_text):
    """
    Encode le texte utilisateur et les textes des blocs avec SBERT.
    Calcule la similarit√© cosinus entre l'utilisateur et chaque bloc.
    
    Retourne un dictionnaire : {BlockID: score_similarit√©}
    """
    print("\nü§ñ Chargement du mod√®le SBERT...")
    model = SentenceTransformer(SBERT_MODEL)
    
    print("üîÑ Encodage du texte utilisateur enrichi...")
    user_embedding = model.encode(user_text, convert_to_tensor=True)
    
    print("üîÑ Encodage des blocs de comp√©tences...")
    block_scores = {}
    
    for block_id, block_text in blocks_text.items():
        # Encoder le bloc
        block_embedding = model.encode(block_text, convert_to_tensor=True)
        
        # Calculer la similarit√© cosinus
        similarity = util.cos_sim(user_embedding, block_embedding)
        score = float(similarity[0][0])
        
        block_scores[block_id] = round(score, 4)
        print(f"   üìä Bloc {block_id} : {score:.4f}")
    
    return block_scores

# =========================
# Fonction principale : Analyse compl√®te
# =========================
def analyze_user_profile():
    """
    Fonction principale qui orchestre toute l'analyse s√©mantique.
    
    Retourne les scores de similarit√© pour chaque bloc.
    """
    print("=" * 60)
    print("üéØ ANALYSE S√âMANTIQUE AM√âLIOR√âE - √âTAPE 3")
    print("=" * 60)
    
    # 1. Charger et concat√©ner les comp√©tences par bloc
    blocks_text = load_and_concatenate_blocks()
    
    # 2. Charger les r√©ponses utilisateur (textes + t√¢ches + outils)
    user_text = load_user_responses()
    
    if not user_text.strip():
        print("\n‚ùå ERREUR : Aucune information trouv√©e dans les r√©ponses utilisateur !")
        return None
    
    # 3. Calculer la similarit√© s√©mantique
    block_scores = calculate_semantic_similarity(user_text, blocks_text)
    
    print("\n" + "=" * 60)
    print("‚úÖ ANALYSE TERMIN√âE")
    print("=" * 60)
    
    return block_scores

# =========================
# Test du module
# =========================
if __name__ == "__main__":
    scores = analyze_user_profile()
    
    if scores:
        print("\nüìä R√âSULTATS FINAUX :")
        print("-" * 40)
        for block_id, score in scores.items():
            print(f"Bloc {block_id} : {score}")